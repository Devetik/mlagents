"""
Implémentation des neurones à dendrites actives pour le continual learning.

Ce module implémente :
1. ActiveDendritesNeuron - Neurones avec modulation dendritique
2. kWTA - Mécanisme k-Winner-Take-All pour la sparsité
3. SynapticIntelligence - Gestion de l'importance synaptique
4. ActiveDendritesNetwork - Réseau complet intégrant tous les composants

Basé sur les travaux de Zenke et al. (2017) et les neurones à dendrites actives.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import List, Tuple, Optional, Dict, Any
import math


class ActiveDendritesNeuron(nn.Module):
    """
    Neurone à dendrites actives avec modulation contextuelle.
    
    Chaque neurone reçoit :
    - Une entrée feedforward classique (état de l'agent)
    - Un vecteur de contexte décrivant la tâche actuelle
    
    L'activation est calculée comme :
    output = feedforward_output * sigmoid(dendritic_modulation)
    """
    
    def __init__(
        self,
        input_size: int,
        context_size: int,
        num_dendritic_segments: int = 8,
        segment_size: int = 16,
        bias: bool = True
    ):
        super().__init__()
        self.input_size = input_size
        self.context_size = context_size
        self.num_dendritic_segments = num_dendritic_segments
        self.segment_size = segment_size
        
        # Poids feedforward classiques
        self.feedforward_weight = nn.Parameter(torch.randn(input_size))
        self.feedforward_bias = nn.Parameter(torch.zeros(1)) if bias else None
        
        # Segments dendritiques pour la modulation contextuelle
        # Shape: (num_segments, segment_size, context_size)
        self.dendritic_segments = nn.Parameter(
            torch.randn(num_dendritic_segments, segment_size, context_size) * 0.1
        )
        
        # Masque pour suivre quels segments sont actifs
        self.register_buffer('active_segments', torch.zeros(num_dendritic_segments))
        
    def forward(self, x: torch.Tensor, context: torch.Tensor) -> torch.Tensor:
        """
        Forward pass du neurone à dendrites actives.
        
        Args:
            x: Entrée feedforward (batch_size, input_size)
            context: Vecteur de contexte (batch_size, context_size)
            
        Returns:
            Activation du neurone (batch_size, 1)
        """
        batch_size = x.shape[0]
        
        # Calcul feedforward classique: t̂ = wᵗx + b
        feedforward_output = torch.sum(x * self.feedforward_weight, dim=1, keepdim=True)
        if self.feedforward_bias is not None:
            feedforward_output += self.feedforward_bias
            
        # Calcul de la modulation dendritique
        # d = max_j(u_jᵗ c) sur tous les segments
        dendritic_modulation = self._compute_dendritic_modulation(context)
        
        # Application de la modulation: output = t̂ * sigmoid(d)
        output = feedforward_output * torch.sigmoid(dendritic_modulation)
        
        return output
    
    def _compute_dendritic_modulation(self, context: torch.Tensor) -> torch.Tensor:
        """
        Calcule la modulation dendritique en trouvant le segment le plus actif.
        
        Args:
            context: Vecteur de contexte (batch_size, context_size)
            
        Returns:
            Modulation dendritique (batch_size, 1)
        """
        batch_size = context.shape[0]
        
        # Calcul des activations pour tous les segments
        # Shape: (batch_size, num_segments, segment_size)
        segment_activations = torch.matmul(
            self.dendritic_segments, 
            context.unsqueeze(1).expand(-1, self.num_dendritic_segments, -1).transpose(1, 2)
        ).transpose(1, 2)
        
        # Trouver le segment le plus actif pour chaque exemple
        # Shape: (batch_size, num_segments)
        segment_scores = torch.max(segment_activations, dim=2)[0]
        
        # Sélection du segment gagnant pour chaque exemple
        winning_segments = torch.argmax(segment_scores, dim=1)
        
        # Mise à jour du masque des segments actifs
        self.active_segments.zero_()
        for i in range(batch_size):
            self.active_segments[winning_segments[i]] = 1
            
        # Retourner l'activation du segment gagnant
        dendritic_modulation = torch.gather(
            segment_scores, 1, winning_segments.unsqueeze(1)
        )
        
        return dendritic_modulation
    
    def get_active_segments(self) -> torch.Tensor:
        """Retourne le masque des segments actifs."""
        return self.active_segments.clone()


class kWTA(nn.Module):
    """
    Mécanisme k-Winner-Take-All pour forcer la sparsité des activations.
    
    Après chaque couche, sélectionne les k activations les plus élevées
    et met les autres à zéro.
    """
    
    def __init__(self, k: int, sparsity_ratio: float = 0.1):
        super().__init__()
        self.k = k
        self.sparsity_ratio = sparsity_ratio
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Applique le mécanisme kWTA.
        
        Args:
            x: Activations de la couche (batch_size, num_neurons)
            
        Returns:
            Activations sparsifiées (batch_size, num_neurons)
        """
        batch_size, num_neurons = x.shape
        
        # Calculer k dynamiquement si nécessaire
        if self.k <= 0:
            k = max(1, int(num_neurons * self.sparsity_ratio))
        else:
            k = min(self.k, num_neurons)
            
        # Trouver les k valeurs les plus élevées pour chaque exemple
        top_k_values, top_k_indices = torch.topk(x, k, dim=1)
        
        # Créer un masque pour les k valeurs gagnantes
        mask = torch.zeros_like(x)
        mask.scatter_(1, top_k_indices, 1.0)
        
        # Appliquer le masque
        sparse_output = x * mask
        
        return sparse_output


class SynapticIntelligence(nn.Module):
    """
    Implémentation de Synaptic Intelligence pour le continual learning.
    
    Chaque paramètre est associé à un coefficient d'importance ω
    qui est mis à jour dynamiquement pendant l'apprentissage.
    """
    
    def __init__(self, model: nn.Module, c: float = 1.0):
        super().__init__()
        self.model = model
        self.c = c  # Coefficient de régularisation
        
        # Dictionnaire pour stocker les valeurs optimales des paramètres
        self.optimal_params = {}
        
        # Dictionnaire pour stocker les coefficients d'importance
        self.importance_weights = {}
        
        # Initialiser les coefficients d'importance
        self._initialize_importance_weights()
        
    def _initialize_importance_weights(self):
        """Initialise les coefficients d'importance pour tous les paramètres."""
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                # Initialiser ω à 0
                self.importance_weights[name] = torch.zeros_like(param.data)
                
    def update_importance_weights(self, loss: torch.Tensor):
        """
        Met à jour les coefficients d'importance basés sur la perte actuelle.
        
        Args:
            loss: Perte actuelle du modèle
        """
        # Calculer les gradients
        self.model.zero_grad()
        loss.backward(retain_graph=True)
        
        # Mettre à jour les coefficients d'importance
        for name, param in self.model.named_parameters():
            if param.requires_grad and param.grad is not None:
                # ω_i += |∇L| (approximation de l'importance)
                self.importance_weights[name] += torch.abs(param.grad.data)
                
    def save_optimal_params(self):
        """Sauvegarde les paramètres optimaux actuels."""
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                self.optimal_params[name] = param.data.clone()
                
    def compute_regularization_loss(self) -> torch.Tensor:
        """
        Calcule le terme de régularisation SI.
        
        Returns:
            Perte de régularisation: c * ∑ ω_i * (θ_i - θ*_i)²
        """
        reg_loss = 0.0
        
        for name, param in self.model.named_parameters():
            if param.requires_grad and name in self.optimal_params:
                # L = c * ∑ ω_i * (θ_i - θ*_i)²
                diff = param - self.optimal_params[name]
                reg_loss += torch.sum(self.importance_weights[name] * diff * diff)
                
        return self.c * reg_loss
    
    def reset_importance_weights(self):
        """Remet à zéro les coefficients d'importance."""
        for name in self.importance_weights:
            self.importance_weights[name].zero_()


class ActiveDendritesLayer(nn.Module):
    """
    Couche complète de neurones à dendrites actives avec kWTA.
    """
    
    def __init__(
        self,
        input_size: int,
        output_size: int,
        context_size: int,
        num_dendritic_segments: int = 8,
        segment_size: int = 16,
        k_wta: int = 0,
        sparsity_ratio: float = 0.1,
        bias: bool = True
    ):
        super().__init__()
        self.input_size = input_size
        self.output_size = output_size
        self.context_size = context_size
        
        # Créer les neurones à dendrites actives
        self.neurons = nn.ModuleList([
            ActiveDendritesNeuron(
                input_size, context_size, num_dendritic_segments, segment_size, bias
            )
            for _ in range(output_size)
        ])
        
        # Mécanisme kWTA
        self.kwta = kWTA(k_wta, sparsity_ratio) if k_wta > 0 else None
        
    def forward(self, x: torch.Tensor, context: torch.Tensor) -> torch.Tensor:
        """
        Forward pass de la couche.
        
        Args:
            x: Entrée (batch_size, input_size)
            context: Contexte (batch_size, context_size)
            
        Returns:
            Sortie de la couche (batch_size, output_size)
        """
        batch_size = x.shape[0]
        
        # Calculer l'activation de chaque neurone
        outputs = []
        for neuron in self.neurons:
            output = neuron(x, context)
            outputs.append(output)
            
        # Concaténer les sorties
        layer_output = torch.cat(outputs, dim=1)
        
        # Appliquer kWTA si activé
        if self.kwta is not None:
            layer_output = self.kwta(layer_output)
            
        return layer_output
    
    def get_active_segments(self) -> List[torch.Tensor]:
        """Retourne les segments actifs de tous les neurones."""
        return [neuron.get_active_segments() for neuron in self.neurons]


class ActiveDendritesNetwork(nn.Module):
    """
    Réseau complet intégrant tous les composants pour le continual learning.
    """
    
    def __init__(
        self,
        input_size: int,
        hidden_sizes: List[int],
        output_size: int,
        context_size: int,
        num_dendritic_segments: int = 8,
        segment_size: int = 16,
        k_wta: int = 0,
        sparsity_ratio: float = 0.1,
        dropout_rate: float = 0.1,
        bias: bool = True
    ):
        super().__init__()
        self.input_size = input_size
        self.hidden_sizes = hidden_sizes
        self.output_size = output_size
        self.context_size = context_size
        
        # Construire les couches
        self.layers = nn.ModuleList()
        
        # Première couche
        layer_sizes = [input_size] + hidden_sizes
        for i in range(len(layer_sizes) - 1):
            layer = ActiveDendritesLayer(
                layer_sizes[i],
                layer_sizes[i + 1],
                context_size,
                num_dendritic_segments,
                segment_size,
                k_wta,
                sparsity_ratio,
                bias
            )
            self.layers.append(layer)
            
        # Couche de sortie (sans dendrites actives)
        self.output_layer = nn.Linear(hidden_sizes[-1], output_size, bias=bias)
        
        # Dropout
        self.dropout = nn.Dropout(dropout_rate) if dropout_rate > 0 else None
        
        # Synaptic Intelligence
        self.si = SynapticIntelligence(self)
        
    def forward(self, x: torch.Tensor, context: torch.Tensor) -> torch.Tensor:
        """
        Forward pass du réseau.
        
        Args:
            x: Entrée (batch_size, input_size)
            context: Contexte (batch_size, context_size)
            
        Returns:
            Sortie du réseau (batch_size, output_size)
        """
        # Passer à travers les couches cachées
        for layer in self.layers:
            x = layer(x, context)
            x = F.relu(x)  # Activation ReLU
            
            if self.dropout is not None:
                x = self.dropout(x)
                
        # Couche de sortie
        output = self.output_layer(x)
        
        return output
    
    def get_active_segments(self) -> List[List[torch.Tensor]]:
        """Retourne les segments actifs de toutes les couches."""
        return [layer.get_active_segments() for layer in self.layers]
    
    def update_importance_weights(self, loss: torch.Tensor):
        """Met à jour les coefficients d'importance SI."""
        self.si.update_importance_weights(loss)
        
    def save_optimal_params(self):
        """Sauvegarde les paramètres optimaux actuels."""
        self.si.save_optimal_params()
        
    def compute_regularization_loss(self) -> torch.Tensor:
        """Calcule le terme de régularisation SI."""
        return self.si.compute_regularization_loss()
    
    def reset_importance_weights(self):
        """Remet à zéro les coefficients d'importance."""
        self.si.reset_importance_weights() 